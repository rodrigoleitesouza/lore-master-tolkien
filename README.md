# ğŸ§™â€â™‚ï¸ Lore-Master J.R.R. Tolkien

Um **assistente inteligente de lore** focado no universo de **J.R.R. Tolkien**, capaz de responder perguntas profundas sobre *O Senhor dos AnÃ©is*, *O Silmarillion* e demais textos, utilizando **RAG (Retrieval-Augmented Generation)** com **LLMs locais via Ollama**.

> ğŸ“š Pergunte sobre personagens, eventos, locais, linhas do tempo e curiosidades da Terraâ€‘mÃ©dia â€” tudo baseado nos documentos que vocÃª indexar.

---

## âœ¨ Principais Funcionalidades

- ğŸ“– **IndexaÃ§Ã£o de documentos** (PDF, TXT, etc.) com embeddings
- ğŸ§  **RAG (Retrieval-Augmented Generation)** usando LangChain
- ğŸ¤– **LLM local** via **Ollama** (sem depender de APIs externas)
- ğŸ—‚ï¸ **Vector Database persistente** com ChromaDB
- ğŸ’¬ **Interface web interativa** com Gradio
- ğŸ³ **Totalmente dockerizado** (Docker + Docker Compose)

---

## ğŸ§© Arquitetura (visÃ£o geral)

```
UsuÃ¡rio (Browser)
      â†“
   Gradio UI
      â†“
LangChain (QA + Memory)
      â†“
ChromaDB (Vector Store)
      â†“
Ollama (LLM local)
```

---

## ğŸš€ Como rodar a aplicaÃ§Ã£o (passo a passo completo)

### 1ï¸âƒ£ PrÃ©â€‘requisitos

Antes de tudo, vocÃª precisa ter instalado:

- **Docker**
- **Docker Compose** (jÃ¡ vem junto nas versÃµes recentes do Docker Desktop)

ğŸ‘‰ Recomendado: **Docker Desktop (Windows / Mac)**

Download oficial:
- https://www.docker.com/products/docker-desktop/

ApÃ³s instalar, **reinicie o computador**.

---

### 2ï¸âƒ£ Verificar se o Docker estÃ¡ funcionando

Abra um terminal (PowerShell, CMD ou Terminal) e rode:

```bash
docker --version
docker compose version
```

Se ambos retornarem versÃ£o, estÃ¡ tudo certo âœ…

---

### 3ï¸âƒ£ Clonar o repositÃ³rio

```bash
git clone https://github.com/SEU_USUARIO/lore-master-tolkien.git
cd lore-master-tolkien
```

---

### 4ï¸âƒ£ Estrutura esperada do projeto

```
lore-master-tolkien/
â”‚
â”œâ”€ app.py
â”œâ”€ config.py
â”œâ”€ requirements.txt
â”œâ”€ Dockerfile
â”œâ”€ docker-compose.yml
â”‚
â”œâ”€ rag/
â”‚  â”œâ”€ embeddings.py
â”‚  â”œâ”€ vectorstore.py
â”‚  â”œâ”€ qa.py
â”‚  â”œâ”€ llm.py
â”‚  â””â”€ memory.py
â”‚
â”œâ”€ data/
â”‚  â”œâ”€ documents/   # coloque aqui os textos da lore
â”‚  â””â”€ chroma/      # base vetorial persistente
â”‚
â””â”€ README.md
```

---

### 5ï¸âƒ£ Subir a aplicaÃ§Ã£o com Docker Compose

Na raiz do projeto, execute:

```bash
docker compose up --build
```

ğŸ“¦ Isso irÃ¡:
- Construir a imagem da aplicaÃ§Ã£o
- Subir o Ollama
- Subir o Loreâ€‘Master
- Criar volumes persistentes

âš ï¸ **Na primeira execuÃ§Ã£o pode demorar**, pois o Docker irÃ¡ baixar dependÃªncias.

---

### 6ï¸âƒ£ Baixar o modelo LLM no Ollama (passo obrigatÃ³rio)

Em outro terminal, execute:

```bash
docker exec -it ollama ollama pull llama3.2
```

Esse passo garante que o modelo exista **dentro do container**.

Verifique com:

```bash
docker exec -it ollama ollama list
```

---

### 7ï¸âƒ£ Acessar a aplicaÃ§Ã£o

Abra o navegador e acesse:

ğŸ‘‰ **http://localhost:7860**

VocÃª verÃ¡ a interface do **Lore-Master J.R.R. Tolkien** ğŸ‰

---

### 8ï¸âƒ£ Fluxo de uso

1. Coloque os arquivos da lore em:
   ```
   data/documents/
   ```
2. Clique em **Indexar documentos**
3. Aguarde o processamento
4. FaÃ§a perguntas no chat

---

## ğŸ› ï¸ Comandos Ãºteis

### Ver logs em tempo real

```bash
docker compose logs -f
```

### Parar a aplicaÃ§Ã£o

```bash
docker compose down
```

### Reiniciar

```bash
docker compose restart
```

---

## âš™ï¸ ConfiguraÃ§Ãµes principais

Arquivo: `config.py`

```python
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
LLM_MODEL = "llama3.2"

CHUNK_SIZE = 500
CHUNK_OVERLAP = 50
```

VocÃª pode trocar o modelo do Ollama facilmente (ex: `mistral`, `llama3`, etc.).

---

## ğŸ“Œ ObservaÃ§Ãµes importantes

- O banco vetorial **Ã© persistente** (fica em `data/chroma`)
- O modelo do Ollama **fica salvo em volume Docker**
- Nenhuma API externa Ã© necessÃ¡ria
- Funciona totalmente offline apÃ³s o setup

---

## ğŸ§™â€â™‚ï¸ VisÃ£o futura (ideias)

- ğŸ” CitaÃ§Ã£o de fontes
- ğŸ§µ HistÃ³rico de conversas
- ğŸŒ Deploy pÃºblico
- ğŸ“š MÃºltiplos universos literÃ¡rios

---

## ğŸ§¡ CrÃ©ditos

Projeto desenvolvido como estudo e aplicaÃ§Ã£o prÃ¡tica de:
- LLMs locais
- RAG
- LangChain
- Docker

Inspirado na obra de **J.R.R. Tolkien**.

> *â€œEven the smallest person can change the course of the future.â€* â€” Galadriel

